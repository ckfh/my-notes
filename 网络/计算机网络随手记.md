# 计算机网络随手记

## 实现可靠的UDP传输

既然UDP以及下层的IP都不提供可靠传输，那么能够入手的地方只有在应用层实现类似TCP协议的可靠传输机制。比如说提供超时重传和序列号确认机制。

## DNS的传输层协议解析

一般使用UDP来支持DNS查询，但是当查询的数据大小超过UDP包承载的大小时，就需要使用TCP协议来进行DNS查询，因为拆分后需要序号来识别前后到达的数据包，因此需要借助TCP协议，而UDP协议包是无序的。

无论是选择 UDP 还是 TCP，最核心的矛盾就在于需要传输的数据包大小，如果数据包小到一定程度，UDP 协议绝对最佳的选择，但是当数据包逐渐增大直到突破 512 字节以及 MTU 1500 字节的限制时，我们也只能选择使用更可靠的 TCP 协议来传输 DNS 查询和相应。

## HTTP

### HTTP1.1优化

HTTP1.1比起1.0的特性有：长连接、支持管道网络传输。

1. 利用缓存避免发送HTTP请求。
    - 源主机在第一次请求到资源后，缓存在本地，后续发出相同请求时，可以直接从本地进行获取，但缓存也不是一直有效，需要设置超时时间，过了超时时间后，再次发出请求，如果此时目的主机的资源仍不变，则目的主机会返回304响应，表示该请求的资源仍有效，目的主机也不会将资源再次发送过来。
2. 减少HTTP请求次数。
    - 减少重定向的请求次数，可以将重定向的工作交给代理服务器，代理服务器收到目的服务器的302响应时，自己去获取数据，然后再返回给源主机，这样源主机就少了一次发送请求的次数。
    - 合并请求，就是合并资源，用一个大资源的请求替换多个小资源的请求，但是当大资源中某一个小资源发生变化后，源主机必须重新下载完整的大资源文件。
    - 延迟发送请求，一般HTML页面会包含许多资源URL，没必要一次性将其获取完成，可以等待用户将页面下拉时，再发出请求。
3. 减少HTTP响应的数据大小(因为响应数据通常比请求要得大)。
    - 无损压缩，适用于文本文件、程序可执行文件、程序源代码等，`Accept-Encoding`和`Content-Encoding`分别是请求方支持的压缩格式以及服务方所选择的压缩格式。
    - 有损压缩，适用于多媒体数据，音频、视频、图片，通过请求头部的`Accept`字段里的【q质量因子】，表述自己所期望的资源质量。

### HTTP2

1. 头部压缩
2. 二进制帧
    - 把响应报文分成了两个帧，头部帧和消息帧，且采用二进制编码，
3. 并发传输
    - 多个stream复用一条TCP连接，达到并发的效果，解决了1.1队头阻塞问题，提高吞吐量。
    - 不同stream帧时可以乱序发送的(因此可以并发不同的stream)，因为每个帧的头部会携带stream ID信息，接收端可以通过ID有序组装HTTP消息，但是同一steam内部的帧必须是严格有序的。
4. 服务器主动推送资源
    - 比如客户端请求HTML页面时，页面中的静态资源同样需要客户端再次发起请求进行获取，而服务器主动推送资源则可以在发送完HTML页面响应后，继续推送静态资源响应。
    - 推送实现是因为客户端使用奇数号的stream，服务端使用偶数号的stream。

总结：

第⼀点，对于常⻅的HTTP头部通过静态表和Huffman编码的⽅式，将体积压缩了近⼀半，⽽且针对后续的请求头部，还可以建⽴动态表，将体积压缩近90%，⼤⼤提⾼了编码效率，同时节约了带宽资源。

不过，动态表并⾮可以⽆限增⼤，因为动态表是会占⽤内存的，动态表越⼤，内存也越⼤，容易影响服务器总体的并发能⼒，因此服务器需要限制HTTP/2连接时⻓或者请求次数。

第⼆点，HTTP/2实现了Stream并发，多个Stream只需复⽤1个TCP连接，节约了TCP和TLS握⼿时间，以及减少了TCP慢启动阶段对流量的影响。不同的Stream ID才可以并发，即时乱序发送帧也没问题，但是同⼀个Stream⾥的帧必须严格有序。

另外，可以根据资源的渲染顺序来设置Stream的优先级，从⽽提⾼⽤户体验。

第三点，服务器⽀持主动推送资源，⼤⼤提升了消息的传输性能，服务器推送资源时，会先发送PUSH_PROMISE帧，告诉客户端接下来在哪个Stream发送资源，然后⽤偶数号Stream发送资源给客户端。

**HTTP/2是基于TCP协议来传输数据的，TCP是字节流协议，TCP层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区⾥的数据返回给HTTP应⽤，那么当「前1个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区⾥，只有等到这1个字节数据到达时，HTTP/2应⽤层才能从内核中拿到数据，这就是HTTP/2队头阻塞问题**。

### HTTP3

美中不足的HTTP2：1.队头阻塞(TCP)、2.TCP与TLS的握手时延迟、3.网络迁移需要重新连接。

HTTP2传输层是TLS1.2+以及TCP，HTTP3传输层是QUIC(TLS1.3)以及UDP。

## HTTPS

## keepalive机制

TCP自身的保活机制只能确保连接无活动之后一定会断开，保证资源的利用率，连接可不可用是另外一回事。

比如TCP三次握手，客户端在第二次握手就完成了连接，服务端在重发5次ACK包后会主动断开此次连接，但客户端此时仍认为连接已经建立，所以此时需要借助心跳机制来快速判断连接是否可用，如果不可用，则立即断开连接，不需要借助保活机制来断开连接。

## 网络分层

- OSI：物理层、数据链路层、网络层、运输层、会话层、表示层、应用层。
- TCP/IP：网络接口层、网际层、运输层、应用层。
- 五层：物理层、数据链路层、网络层、运输层、应用层。

## IPv6

IPv6是128位，不需要DHCP也能自动实现分配IP地址。

对比IPv4首部，取消了首部检验和字段、取消了分片/重新组装等相关字段、取消选项字段，简化首部结构。

有应对伪造IP地址的网络安全功能以及防止线路窃听的功能。

## 帧

- 单播帧的意思就是该帧是发送给一个特定的主机，但因为总线特性仍然会将该帧发送给其它主机；
- 多播帧的意思就是该帧是发送给多个特定的主机，但因为总线特性仍然会将该帧发送给其它主机；
- 广播帧的意思就是该帧是发送给全部主机的；

因此，单播、多播、广播的意思是发送主机的数量，而不是发送的行为。

如果两个帧同时到达集线器，则会发生碰撞，发生碰撞的帧会发送给所有主机。

交换机会缓存从各主机收到的帧，然后逐个发送给目的主机，因此不需要进行碰撞检测。

交换机是全双工工作模式，即可以同时发送帧和接收帧，因此交换机的速率就是连接到该交换机的主机速率，不会对速率进行均分。

用户主机无法识别IEEE802.1Q帧，会将其直接丢弃。

## 路由

路由聚合的目的是为了减少路由表上的冗余，即将多个属于同一路由器的cidr网络聚合成一个cidr超网，这样分组也能够知道应该将该分组转发给目的路由器，等到达目的路由器后再进行下一步的路由。

优先选择前缀更长的进行转发，因为这样的路由更具体。

将IP地址和子网掩码相与可以得到该网络的网络地址。

子网掩码就是用来区分各个网络用的，将两个不同的IP地址和同一个子网掩码想与得到的网络地址如果相同，则在同一个子网当中。

变长子网掩码的一个快速划分子网的方法就是将可操作范围的IP地址从0开始，根据地址块长度，将剩余的位数都替换成1作为广播地址就可以划分出一个子网所用的全部地址，而下一个子网就从之前的子网广播地址加1后，继续按照地址块长度进行划分。

注意按地址块长度从小到大或按地址数量从大到小开始进行划分。

默认路由条目用于替代具有相同下一跳的路由条目，默认路由的网络前缀最短为0位，当路由器接收到不存在于路由表中的目的网络，将走默认路由进行转发。

特定主机路由的子网掩码是255.255.255.255（特例），和其所在网络的子网掩码位数不同，这是为了区分它是特定主机路由，它的网络前缀最长，路由最具体，转发分组时，将优先对其进行转发。
当有多个路由项下一跳相同时，将匹配最长前缀。

路由选择协议用于路由器获取路由信息。

RIP路由选择协议仅适用于小型网络，收敛的意思是得到该路由到每个目的网络的最短路由。

OSPF推出区域的目的是为了减少洪泛法的发送路由器数量。

## 复用

复用的意思不是说将不同协议的报文一起封装在下一层的一个协议报文中，而是说下一层的协议报文可以作为上一层不同协议报文的载体，就是一个盒子被设定为可以装不同的东西，但一次只装一个，不是说一个盒子只能装某种特定的东西。

因为我们在每一层就是对上一层的某种协议报文进行再封装，添加所谓的首部，使之成为当前协议的报文。

## 流控

TCP是每发送一个报文段都必须收到相应的确认报文段，可以成组发送，成组收到确认。

**流量控制是为了防止发送方速率过快而接收方处理速度过慢导致数据丢失，即让发送方速率不要太快，让接收方来得及接收**。

利用滑动窗口机制在TCP连接上实现对发送方的流量控制。

如果硬要说什么时候触发流量控制，那就是接收方再次发送新的窗口大小来对发送方进行流量控制。

## 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏。这种情况就叫拥塞。

链路容量即带宽，交换节点中的缓存和处理机等，都是网络资源。

正常来说，输入负荷越大，整个网络的吞吐量应该上升，理想拥塞控制就是首先吞吐量和输入负荷形成正相关，在超过某一输入负载后，网络整体吞吐量维持在一个稳定值，但没有拥塞控制的网络就会出现超过某一输入负荷后，整体吞吐量迅速下降，直至为零，导致网络瘫痪。

TCP的拥塞控制算法：

前提：单方向、接收方缓存空间足够大，因而发送方的窗口大小由拥塞程度决定、以最大报文段个数为讨论单位。

**拥塞的依据是没有按时收到应当到达的确认报文，即发送方发生了超时重传**。

### 慢开始

慢开始是指一开始向网络中注入的报文段少，而不是拥塞窗口增长速度慢，它可是指数级别的增长。

引入拥塞窗口后，发送方的实际发送窗口应该是min[拥塞窗口，接收窗口]。

维护一个【慢开始门限】，拥塞窗口小于门限时，执行慢开始算法，大于时执行拥塞避免算法，等于时两者皆可。

**慢开始算法就是拥塞窗口从1开始，逐步乘2直至达到门限(指数)，在这期间发送方可以快速发送完窗口内可发的报文段**。

### 拥塞避免

不能完全避免拥塞，只是在拥塞避免阶段将窗口控制为【线性增长】，使网络较不容易出现拥塞。

如果慢开始阶段窗口大小乘2后直接超过门限值，则在当前窗口值直接进行拥塞避免算法。

从门限值开始，拥塞窗口逐步加1(线性)，由于窗口越来越大， 可发送的报文段越多，加大了发生丢失的概率，即超时重传出现概率增大。

发生【超时重传】时，将门限值更新为此时拥塞窗口的一半，然后将拥塞窗口置为1，重新执行慢开始算法。

有时个别报文段的丢失不是因为拥塞而引起的，这将导致发送方超时重传，误认为发生了拥塞。

### 快重传

使发送方尽快进行重传，而不是等待超时重传计时器超时再重传，这要求：

1. 接收方不要等待自己发送数据时才进行”捎带确认“，而是立即发送确认。
2. 即使报文段失序也要立即发出对已收到报文段的重复确认。
3. 发送一旦收到3个连续的重复确认，就立即重传。

当该过程小于超时计时器的计时时，发送方就不会认为发生了拥塞，也不会将拥塞窗口降为1，而是利用快恢复的原理将窗口值降为一半或更大。

但如果该过程超过计时，那就还是会让拥塞窗口降为1，重新执行慢开始算法。

### 快恢复

如果收到3个连续的重复确认，就知道只是丢失了个别报文段，不启动慢开始算法，而执行快恢复算法。

将门限和拥塞窗口设为当前窗口的一半，直接执行拥塞避免算法。

有的则是将拥塞窗口设得大一些，例如等于新的门限值加3。

### 超时重传的时间选择

它应该略大于加权平均时间RTT_s的值。

## 确认报文段

确认报文段是接收方表达希望收到的下一个报文段序号，即使发送方发送了后续的多个报文段，接收方也只会发送之前希望得到的确认报文段，直到收到缺失的报文段，此时才对之前正确收到的报文段进行发送确认。

## 端口号

端口号的使用，比如发送DNS请求报文给DNS服务器，那么客户端发起DNS请求的进程可以随意选择一个端口号作为源端口，但是目的端口必须选择为53，表示将该报文转交给服务器上层的DNS进程，服务器收到该报文，查看到目的端口为53，则向DNS进程交付该报文，解析出DNS对应的IP地址，然后发送响应报文给客户端进程，其中源端口和目的端口与请求报文刚好相反，因为我要发送给发起了DNS请求的进程。

## TCP可靠传输

TCP可靠传输的实现：

1. 基于以字节为单位的滑动窗口实现可靠传输。
2. 接收方只能对按序收到的数据中的最高序号给出确认。

细节：

1. 发送方的发送窗口并不总是和接收方的接收窗口一样大。
2. 不按序到达的数据应该如何处理。
3. 累计确认和捎带确认机制。

### TCP最大连接数

理论公式：最大TCP连接数=客户端的IP数×客户端的端口数。

对于IPv4，IP数最多为2的32次方，端口数最多为2的16次方，也就是服务端最大TCP连接数为2的48次方。

但是，受到**文件描述符限制**，Socket都是文件，首先要通过`ulimit -n`配置文件描述符的数目。

另一个是**内存限制**，每个TCP连接都要占用一定的内存，操作系统内存是有限的。

## TCP连接与释放

ack=x，表示的是请求发送方希望接收的下一个报文段序号值。

### 三报文握手

状态变化：关闭(C/S)/监听(S)/同步已发送(C)/同步已接收(S)/连接已建立(C/S)。

- 1号报文(SYN=1, seq=x(初始化时的序号))不能携带数据。
- 2号报文(SYN=1, ACK=1, seq=y(初始化时的序号), ack=x+1)不能携带数据。
- 3号报文(ACK=1, seq=x+1, ack=y+1)**可以携带数据**，如果不携带数据则建立成功后的报文段序号则还是从x+1开始。

如果仅采用两报文握手，假设在两报文握手之前已经发送了一个连接请求报文，此时两报文握手建立连接，数据传输，释放连接，双方进入关闭状态(注意，关闭状态很重要)，此时之前的连接请求报文到达服务器，服务器误以为客户端此时需要建立连接，于是发回确认连接，客户端由于处于”关闭“状态，因此不理睬该确认，但是服务器已经处于连接已建立状态(因为是两报文握手，此时应该处于该状态)，这会导致白白浪费资源，如果是三报文请求，由于客户端处于”关闭“状态，因此不会发送3号报文，而服务端收不到3号报文也不会从同步已接收状态进入连接已建立状态。

- 两次握手：无法避免历史错误连接的初始化，浪费接收方的资源；
- 四次握手：TCP协议的设计可以让我们同时传递ACK和SYN两个控制信息，减少了通信次数，所以不需要使用更多的通信次数传输相同的信息；

### 半连接和全连接队列

服务端收到SYN报文时，就把该连接放到半连接队列，然后发送SYN+ACK。

服务端收到ACK报文时，就把之前的连接从半连接队列放到全连接队列，等待应用程序处理。

【应用程序处理过慢】，会导致全连接队列被占满。

【遭受SYN攻击】，会导致半连接队列被占满。

### SYN攻击

黑客发送多个SYN报文到服务端，服务端返回SYN和ACK报文，进入“同步已接收”状态，但发出去的报文并不会被接收，导致【服务端半连接队列】被占满，无法提供服务。

### 四报文挥手

状态变化：连接已建立(C/S)/终止等待1(C)/关闭等待(S)/终止等待2(C)/最后确认(S)/时间等待(C)/关闭(C/S)。

- 1号(FIN=1, ACK=1, seq=u, ack=v)即使不携带数据，也要消耗一个序号。
- 2号(ACK=1, seq=v, ack=u+1)接收到2号报文时，客户端到服务器的连接就释放了，半关闭状态，表示客户端进程已经没有数据要发送了，但如果服务器进程还要数据要发送，则客户端仍需要接收。
- 3号(FIN=1, ACK=1, seq=w, ack=u+1)。
- 4号(ACK=1, seq=u+1, ack=w+1)。

TCP四次挥手可能也只有三次，FIN / ACK,FIN / ACK，这是因为服务器将自己的ACK包和FIN包组合在一起发送了。

### 为什么挥手需要四次

- 首先发送FIN包，表示自身不再发送数据但还能接收数据；
- 然后收到FIN包时，先回一个ACK包，但是自身可能还有数据需要发送，等到所有数据发送完毕时，再发送FIN包。

所以，为了【等待剩余数据发送】，服务端的ACK和FIN包通常要分开发送，如果说没有剩余数据要发送，当然也可以ACK和FIN合在一起发送。

### 时间等待的作用

客户端在时间等待状态必须等待2MSL时间才能进入关闭状态。MSL表示最长报文段寿命，建议2分钟。

- 为什么？仍然是”关闭“状态的原因，假设说客户端发送完4号报文就处于关闭状态，万一4号报文丢失，则服务端会超时重传3号报文，而客户端此时已经无法再发送4号报文，这会导致服务端一直处于最后确认状态无法进入关闭状态。
- 另外客户端发送完4号报文的2MSL时间内，可以确保本次客户端和服务端这次连接内所产生的报文段都从网络中消失，使下一个新的TCP连接中不会收到旧连接的报文段。

### 建立连接后，客户端故障

TCP有一个保活机制。

定义⼀个时间段，在这个时间段内，如果【没有任何连接相关】的活动，TCP 保活机制会开始作⽤，每隔⼀个时间间隔，发送⼀个探测报⽂，该探测报⽂包含的数据⾮常少，如果连续⼏个探测报⽂都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应⽤程序。

开启保活后的几种情况：

1. 对端程序是【正常】⼯作的。当 TCP 保活的探测报⽂发送给对端, 对端会正常响应，这样 TCP 保活时间会被【重置】，等待下⼀个 TCP 保活时间的到来。
2. 对端程序【崩溃并重启】。当 TCP 保活的探测报⽂发送给对端后，对端是可以响应的，【但由于没有该连接的有效信息，会产⽣⼀个 RST 报⽂】，这样很快就会发现 TCP 连接已经被重置。
3. 对端程序【崩溃】，或对端由于其他原因导致报⽂不可达。当 TCP 保活的探测报⽂发送给对端后，⽯沉⼤海，没有响应，连续⼏次，达到保活探测次数后，TCP 会报告该 TCP 连接已经【死亡】。

### 后续

从以上可以看出，这些措施都是为了保证服务器(TCP进程)的正常运行。

客户端和服务端主动发起关闭连接的一方才有TIME_WAIT状态。

发送FIN包表示自身没有数据要发送了，但是需要等待对方将剩余的数据发送过来，如果有的话，等到对方也没有数据要发送时，对方也会发送一个FIN包过来。

### MSL时间确认

**MSL报文最大生存时间，是任何报文在网络上存在的最长时间，超过这个时间报文将丢弃**。

这可以联想到IP协议头中的TTL字段，TTL字段每经过一个路由器都会减1，减到0时数据报将被丢弃，并发送ICMP通知源主机。

MSL的单位是时间，TTL是经过的路由跳数，MSL应该大于等于TTL消耗为0的时间。

**等待2MSL的一个比较合理的解释是：网络中存在发送方的数据包，接收方接收到数据包处理后又向对方发送响应，一来一回需要2倍的时间**。

比如被动关闭方没有收到发送FIN报文后的ACK报文，就会触发超时重发FIN报文，另一方收到FIN报文后，重发ACK报文给被动关闭方。

**2MSL是收到FIN报文后发送ACK报文才开始计时，如果TIME_WAIT时间内ACK没有到达对方，又收到了对方的FIN，将重新计时**。

### TIME_WAIT过多的危害

如果服务器有处于TIME_WAIT状态的TCP，则说明是由服务器主动发起的断开请求。

过多会造成：1.**服务端内存占用**。2.**客户端端口占用**。

客户端TIME_WAIT过多，导致端口被占用，无法创建新连接。

服务器TIME_WAIT过多，理论上服务器可以建立很多连接，且可以只监听一个端口，但是会把连接丢给线程池处理，线程池中存在过多一直不断开的连接，会导致资源被占用，处理不来新的连接。

### 如何优化TIME_WAIT

1. 打开`net.ipv4.tcp_tw_reuse`和`net.ipv4.tcp_timestamps`选项；
    - 【复用处于`TIME_WAIT`的`socket`为新的连接所用】。`tcp_tw_reuse`功能只能用客户端（连接发起方），因为开启了该功能，在调用`connect()`函数时，内核会随机找一个`time_wait`状态超过1秒的连接给新的连接复用。
2. `net.ipv4.tcp_max_tw_buckets`一旦超过这个值时，【系统就会将所有的`TIME_WAIT`连接状态重置】。
3. 程序中使用`SO_LINGER`如果`l_onoff`为非0， 且`l_linger`值为0，【那么调用`close`后，会立该发送一个`RST`标志给对端，该`TCP`连接将跳过四次挥手，也就跳过了`TIME_WAIT`状态，直接关闭】。

简单来说：

1. 复用处于TIME_WAIT的连接。
2. 超时重置。
3. 跳过四次挥手，直接关闭连接。

### TCP快连接

一个HTTP的完整交互需要2.5个RTT，TCP占用了1.5个RTT，HTTP占用了1个RTT，如果把GET请求放到第三次握手中，则只需要2个RTT。
Linux3.7内核版本中，提供了TCP FAST OPEN功能，可以减少TCP连接建立的时延。
第一次建立连接时，服务器二次握手产生一个加密COOKIE给到客户端，客户端缓存COOKIE，第一次发起请求时仍需要2个RTT。
下次请求时，客户端在SYN包带上COOKIE发给服务端(即SYN+COOKIE+HTTP GET)，可以跳过三次握手的过程，因为COOKIE中维护了一些信息，服务端可以从COOKIE获取TCP相关信息，这个时候发起HTTP GET 请求只需要1个RTT。

## TCP/IP拆分数据

TCP协议为了保证可靠性，会通过IP协议的MTU计算出MSS并根据MSS分段避免IP协议对数据包进行分片。

因为IP协议对数据包的分片对上层是透明的，如果协议不根据MTU做一些限制，那么IP协议的分片会导致部分数据包失去传输层协议头，一旦数据包发生丢失就只能丢弃全部数据。

IP协议拆分数据是因为物理设备的限制，一次能够传输的数据**由路径上MTU最小的设备决定**，一旦IP协议传输的数据包超过MTU的限制就会发生丢包，所以我们需要通过路径MTU发现获取传输路径上的MTU限制。

**TCP协议拆分数据是为了保证传输的可靠性和顺序，作为可靠的传输协议，为了保证数据的传输顺序，它需要为每一个数据段增加包含序列号的TCP协议头，如果数据段大小超过了IP协议的MTU限制，就会带来更多额外的重传和重组开销，影响性能**。

## 粘包问题

TCP协议是基于字节流的传输层协议，其中不存在消息和数据包的概念。

应用层协议没有使用基于长度或者基于终结符的消息边界，导致多个消息的粘连。

当应用层协议使用TCP协议传输数据时，TCP协议可能会将应用层发送的数据分成多个包依次发送，而数据的接收方收到的数据段可能有多个『应用层数据包』组成，所以当应用层从TCP缓冲区中读取数据时发现粘连的数据包时，需要对收到的数据进行拆分。

我们使用Content-Length头表示HTTP消息的负载大小，当应用层协议解析到足够的字节数后，就能从中分离出完整的HTTP消息，无论发送方如何处理对应的数据包，我们都可以遵循这一规则完成HTTP消息的重组。

## 协议

DHCP用来自动配置一个网络中各主机的IP地址。

DNS将对用户友好的域名转换为其背后的IP地址。

域名相同不代表等级相同，比如顶级域名`.com`和二级域名`.com.cn`。

1. 在DNS高速缓存表中查找对应的IP地址。
2. 向DNS服务器进行查询。

本地->根->顶级->权限。

DNS选择UDP还是TCP：无论是选择UDP还是TCP，最核心的矛盾就在于需要传输的数据包大小，如果数据包小到一定程度，UDP协议绝对最佳的选择，但是当数据包逐渐增大直到突破512字节以及MTU1500字节的限制时，我们也只能选择使用更可靠的TCP协议来传输DNS查询和相应。

## 其它

假设向服务器请求某个HTML文档到本地，则无论是文档本身还是文档当中所包含的图片，脚本文件，样式文件都必须各自发起一次请求将其取回到本地，由浏览器组织并渲染出页面展示给用户。

HTTP是面向文本的，报文中的每一个字段都是一些ASCII码串，每个字段的长度不确定。

HTTP报文会被封装在TCP报文的数据载荷部分。

Cookie是一种对无状态的HTTP进行状态化的技术。

HTTP的1.1版本支持持续连接方式，当请求头中的connection字段为keep-alive时，表示希望建立持续连接，但如果是close，就表示服务器发送完文档后即可释放连接。
