# 笔记

## 网络分层

- OSI：物理层、数据链路层、网络层、运输层、会话层、表示层、应用层。
- TCP/IP：网络接口层、网际层、运输层、应用层。
- 五层：物理层、数据链路层、网络层、运输层、应用层。

## v6

IPv6是128位，不需要DHCP也能自动实现分配IP地址。

取消了首部检验和字段、取消了分片/重新组装等相关字段、取消选项字段。

## 帧

- 单播帧的意思就是该帧是发送给一个特定的主机，但因为总线特性仍然会将该帧发送给其它主机；
- 多播帧的意思就是该帧是发送给多个特定的主机，但因为总线特性仍然会将该帧发送给其它主机；
- 广播帧的意思就是该帧是发送给全部主机的；

因此，单播、多播、广播的意思是发送主机的数量，而不是发送的行为。

如果两个帧同时到达集线器，则会发生碰撞，发生碰撞的帧会发送给所有主机。

交换机会缓存从各主机收到的帧，然后逐个发送给目的主机，因此不需要进行碰撞检测。

交换机是全双工工作模式，即可以同时发送帧和接收帧，因此交换机的速率就是连接到该交换机的主机速率，不会对速率进行均分。

用户主机无法识别IEEE802.1Q帧，会将其直接丢弃。

## 路由

路由聚合的目的是为了减少路由表上的冗余，即将多个属于同一路由器的cidr网络聚合成一个cidr超网，这样分组也能够知道应该将该分组转发给目的路由器，等到达目的路由器后再进行下一步的路由。

优先选择前缀更长的进行转发，因为这样的路由更具体。

将IP地址和子网掩码相与可以得到该网络的网络地址。

子网掩码就是用来区分各个网络用的，将两个不同的IP地址和同一个子网掩码想与得到的网络地址如果相同，则在同一个子网当中。

变长子网掩码的一个快速划分子网的方法就是将可操作范围的IP地址从0开始，根据地址块长度，将剩余的位数都替换成1作为广播地址就可以划分出一个子网所用的全部地址，而下一个子网就从之前的子网广播地址加1后，继续按照地址块长度进行划分。

注意按地址块长度从小到大或按地址数量从大到小开始进行划分。

默认路由条目用于替代具有相同下一跳的路由条目，默认路由的网络前缀最短为0位，当路由器接收到不存在于路由表中的目的网络，将走默认路由进行转发。

特定主机路由的子网掩码是255.255.255.255（特例），和其所在网络的子网掩码位数不同，这是为了区分它是特定主机路由，它的网络前缀最长，路由最具体，转发分组时，将优先对其进行转发。
当有多个路由项下一跳相同时，将匹配最长前缀。

路由选择协议用于路由器获取路由信息。

RIP路由选择协议仅适用于小型网络，收敛的意思是得到该路由到每个目的网络的最短路由。

OSPF推出区域的目的是为了减少洪泛法的发送路由器数量。

## 复用

复用的意思不是说将不同协议的报文一起封装在下一层的一个协议报文中，而是说下一层的协议报文可以作为上一层不同协议报文的载体，就是一个盒子被设定为可以装不同的东西，但一次只装一个，不是说一个盒子只能装某种特定的东西。

因为我们在每一层就是对上一层的某种协议报文进行再封装，添加所谓的首部，使之成为当前协议的报文。

## 流控

TCP是每发送一个报文段都必须收到相应的确认报文段，可以成组发送，成组收到确认。

**流量控制是为了防止发送方速率过快而接收方处理速度过慢导致数据丢失，即让发送方速率不要太快，让接收方来得及接收**。

利用滑动窗口机制在TCP连接上实现对发送方的流量控制。

如果硬要说什么时候触发流量控制，那就是接收方再次发送新的窗口大小来对发送方进行流量控制。

## 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏。这种情况就叫拥塞。

链路容量即带宽，交换节点中的缓存和处理机等，都是网络资源。

正常来说，输入负荷越大，整个网络的吞吐量应该上升，理想拥塞控制就是首先吞吐量和输入负荷形成正相关，在超过某一输入负载后，网络整体吞吐量维持在一个稳定值，但没有拥塞控制的网络就会出现超过某一输入负荷后，整体吞吐量迅速下降，直至为零，导致网络瘫痪。

TCP的拥塞控制算法：

前提：单方向、接收方缓存空间足够大，因而发送方的窗口大小由拥塞程度决定、以最大报文段个数为讨论单位。

**拥塞的依据是没有按时收到应当到达的确认报文，即发送方发生了超时重传**。

### 慢开始

慢开始是指一开始向网络中注入的报文段少，而不是拥塞窗口增长速度慢，它可是指数级别的增长。

引入拥塞窗口后，发送方的实际发送窗口应该是min[拥塞窗口，接收窗口]。

维护一个慢开始门限，拥塞窗口小于门限时，慢开始算法，大于时拥塞避免算法，等于时两者皆可。

**慢开始算法就是拥塞窗口从1开始，逐步乘2直至达到门限(指数)，在这期间发送方可以快速发送完窗口内可发的报文段**。

### 拥塞避免

不能完全避免拥塞，只是在拥塞避免阶段将窗口控制为线性增长，使网络较不容易出现拥塞。

如果乘2后直接超过门限，则在当前窗口值直接进行避免算法。

从门限值开始，拥塞窗口逐步加1(线性)，由于窗口越来越大， 可发送的报文段越多，加大了发生丢失的概率，即超时重传出现概率增大。

发生超时重传时，将门限值更新为此时拥塞窗口的一半，然后将拥塞窗口置为1，重新开始慢开始算法。

有时个别报文段的丢失不是因为拥塞而引起的，这将导致发送方超时重传，误认为发生了拥塞。

### 快重传

使发送方尽快进行重传，而不是等待超时重传计时器超时再重传，这要求：

1. 接收方不要等待自己发送数据时才进行”捎带确认“，而是立即发送确认。
2. 即使报文段失序也要立即发出对已收到报文段的重复确认。
3. 发送一旦收到3个连续的重复确认，就立即重传。

当该过程小于超时计时器的计时时，发送方就不会认为发生了拥塞，也不会将拥塞窗口降为1，而是利用快恢复的原理降为一半或更多。

但如果该过程超过计时，那就还是会让拥塞窗口降为1，重新慢开始。

### 快恢复

如果收到3个连续的重复确认，就知道只是丢失了个别报文段，不启动慢开始算法，而执行快恢复算法。

将门限和拥塞窗口设为当前窗口的一半，直接执行拥塞避免算法。

有的则是将拥塞窗口设得大一些，例如等于新的门限值加3。

### 超时重传的时间选择

它应该略大于加权平均时间RTT_s的值。

## 确认报文段

确认报文段是接收方表达希望收到的下一个报文段序号，即使发送方发送了后续的多个报文段，接收方也只会发送之前希望得到的确认报文段，直到收到缺失的报文段，此时才对之前正确收到的报文段进行发送确认。

## 端口号

端口号的使用，比如发送DNS请求报文给DNS服务器，那么客户端发起DNS请求的进程可以随意选择一个端口号作为源端口，但是目的端口必须选择为53，表示将该报文转交给服务器上层的DNS进程，服务器收到该报文，查看到目的端口为53，则向DNS进程交付该报文，解析出DNS对应的IP地址，然后发送响应报文给客户端进程，其中源端口和目的端口与请求报文刚好相反，因为我要发送给发起了DNS请求的进程。

## TCP可靠传输

TCP可靠传输的实现：

1. 基于以字节为单位的滑动窗口实现可靠传输。
2. 接收方只能对按序收到的数据中的最高序号给出确认。

细节：

1. 发送方的发送窗口并不总是和接收方的接收窗口一样大。
2. 不按序到达的数据应该如何处理。
3. 累计确认和捎带确认机制。

## TCP连接与释放

ack=x，表示的是请求发送方希望接收的下一个报文段序号值。

### 三报文握手

状态变化：关闭/监听/同步已发送/同步已接收/连接已建立。

- 1号报文(SYN=1, seq=x(初始化时的序号))不能携带数据。
- 2号报文(SYN=1, ACK=1, seq=y(初始化时的序号), ack=x+1)不能携带数据。
- 3号报文(ACK=1, seq=x+1, ack=y+1)可以携带数据，如果不携带数据则建立成功后的报文段序号则还是从x+1开始。

如果仅采用两报文握手，假设在两报文握手之前已经发送了一个连接请求报文，此时两报文握手建立连接，数据传输，释放连接，双方进入关闭状态(注意，关闭状态很重要)，此时之前的连接请求报文到达服务器，服务器误以为客户端此时需要建立连接，于是发回确认连接，客户端由于处于”关闭“状态，因此不理睬该确认，但是服务器已经处于连接已建立状态(因为是两报文握手，此时应该处于该状态)，这会导致白白浪费资源，如果是三报文请求，由于客户端处于”关闭“状态，因此不会发送3号报文，而服务端收不到3号报文也不会从同步已接收状态进入连接已建立状态。

- 两次握手：无法避免历史错误连接的初始化，浪费接收方的资源；
- 四次握手：TCP协议的设计可以让我们同时传递ACK和SYN两个控制信息，减少了通信次数，所以不需要使用更多的通信次数传输相同的信息；

### 四报文挥手

状态变化：连接已建立/终止等待1/关闭等待/终止等待2/最后确认/时间等待/关闭。

- 1号(FIN=1, ACK=1, seq=u, ack=v)即使不携带数据，也要消耗一个序号。
- 2号(ACK=1, seq=v, ack=u+1)接收到2号报文时，客户端到服务器的连接就释放了，半关闭状态，表示客户端进程已经没有数据要发送了，但如果服务器进程还要数据要发送，则客户端仍需要接收。
- 3号(FIN=1, ACK=1, seq=w, ack=u+1)。
- 4号(ACK=1, seq=u+1, ack=w+1)。

### 时间等待的作用

客户端在时间等待状态必须等待2MSL时间才能进入关闭状态。MSL表示最长报文段寿命，建议2分钟。

为什么？仍然是”关闭“状态的原因，假设说客户端发送完4号报文就处于关闭状态，万一4号报文丢失，则服务端会超时重传3号报文，而客户端此时已经无法再发送4号报文，这会导致服务端一直处于最后确认状态无法进入关闭状态。

另外客户端发送完4号报文的2MSL时间内，可以确保本次客户端和服务端这次连接内所产生的报文段都从网络中消失，使下一个新的TCP连接中不会收到旧连接的报文段。

保活计时器：确保服务端不会白白等待故障客户端的请求到来。

### 后续

从以上可以看出，这些措施都是为了保证服务器(TCP进程)的正常运行。

客户端和服务端主动发起关闭连接的一方才有TIME_WAIT状态。

发送FIN包表示自身没有数据要发送了，但是需要等待对方将剩余的数据发送过来，如果有的话，等到对方也没有数据要发送时，对方也会发送一个FIN包过来。

### MSL时间确认

MSL报文最大生存时间，是任何报文在网络上存在的最长时间，超过这个时间报文将丢弃。

这可以联想到IP协议头中的TTL字段，TTL字段每经过一个路由器都会减1，减到0时数据报将被丢弃，并发送ICMP通知源主机。

MSL的单位是时间，TTL是经过的路由跳数，MSL应该大于等于TTL消耗为0的时间。

等待2MSL的一个比较合理的解释是：网络中存在发送方的数据包，接收方接收到数据包处理后又向对方发送响应，一来一回需要2倍的时间。

比如被动关闭方没有收到发送FIN报文后的ACK报文，就会触发超时重发FIN报文，另一方收到FIN报文后，重发ACK报文给被动关闭方。

2MSL是收到FIN报文后发送ACK报文才开始计时，如果TIME_WAIT时间内ACK没有到达对方，又收到了对方的FIN，将重新计时。

### TIME_WAIT过多的危害

如果服务器有处于TIME_WAIT状态的TCP，则说明是由服务器主动发起的断开请求。

过多会造成：1.内存占用。2.端口占用。

客户端TIME_WAIT过多，导致端口被占用，无法创建新连接。

服务器TIME_WAIT过多，理论上服务器可以建立很多连接，且可以只监听一个端口，但是会把连接丢给线程池处理，线程池中存在过多一直不断开的连接，会导致资源被占用，处理不来新的连接。

### 如何优化TIME_WAIT

1. 打开`net.ipv4.tcp_tw_reuse`和`net.ipv4.tcp_timestamps`选项；复用处于`TIME_WAIT`的`socket`为新的连接所用。`tcp_tw_reuse`功能只能用客户端（连接发起方），因为开启了该功能，在调用`connect()`函数时，内核会随机找一个`time_wait`状态超过1秒的连接给新的连接复用。
2. `net.ipv4.tcp_max_tw_buckets`一旦超过这个值时，系统就会将所有的`TIME_WAIT`连接状态重置。
3. 程序中使用`SO_LINGER`如果`l_onoff`为非0， 且`l_linger`值为0，那么调用`close`后，会立该发送一个`RST`标志给对端，该`TCP`连接将跳过四次挥手，也就跳过了`TIME_WAIT`状态，直接关闭。

### TCP快连接

一个HTTP的完整交互需要2.5个RTT，TCP占用了1.5个RTT，HTTP占用了1个RTT，如果把GET请求放到第三次握手中，则只需要2个RTT。
Linux3.7内核版本中，提供了TCP FAST OPEN功能，可以减少TCP连接建立的时延。
第一次建立连接时，服务器二次握手产生一个加密COOKIE给到客户端，客户端缓存COOKIE，第一次发起请求时仍需要2个RTT。
下次请求时，客户端在SYN包带上COOKIE发给服务端(即SYN+COOKIE+HTTP GET)，可以跳过三次握手的过程，因为COOKIE中维护了一些信息，服务端可以从COOKIE获取TCP相关信息，这个时候发起HTTP GET 请求只需要1个RTT。

## TCP/IP拆分数据

TCP协议为了保证可靠性，会通过IP协议的MTU计算出MSS并根据MSS分段避免IP协议对数据包进行分片。

因为IP协议对数据包的分片对上层是透明的，如果协议不根据MTU做一些限制，那么IP协议的分片会导致部分数据包失去传输层协议头，一旦数据包发生丢失就只能丢弃全部数据。

IP协议拆分数据是因为物理设备的限制，一次能够传输的数据**由路径上MTU最小的设备决定**，一旦IP协议传输的数据包超过MTU的限制就会发生丢包，所以我们需要通过路径MTU发现获取传输路径上的MTU限制。

**TCP协议拆分数据是为了保证传输的可靠性和顺序，作为可靠的传输协议，为了保证数据的传输顺序，它需要为每一个数据段增加包含序列号的TCP协议头，如果数据段大小超过了IP协议的MTU限制，就会带来更多额外的重传和重组开销，影响性能**。

## 粘包问题

TCP协议是基于字节流的传输层协议，其中不存在消息和数据包的概念。

应用层协议没有使用基于长度或者基于终结符的消息边界，导致多个消息的粘连。

当应用层协议使用TCP协议传输数据时，TCP协议可能会将应用层发送的数据分成多个包依次发送，而数据的接收方收到的数据段可能有多个『应用层数据包』组成，所以当应用层从TCP缓冲区中读取数据时发现粘连的数据包时，需要对收到的数据进行拆分。

我们使用Content-Length头表示HTTP消息的负载大小，当应用层协议解析到足够的字节数后，就能从中分离出完整的HTTP消息，无论发送方如何处理对应的数据包，我们都可以遵循这一规则完成HTTP消息的重组。

## 协议

DHCP用来自动配置一个网络中各主机的IP地址。

DNS将对用户友好的域名转换为其背后的IP地址。

域名相同不代表等级相同，比如顶级域名`.com`和二级域名`.com.cn`。

1. 在DNS高速缓存表中查找对应的IP地址。
2. 向DNS服务器进行查询。

本地->根->顶级->权限。

DNS选择UDP还是TCP：无论是选择UDP还是TCP，最核心的矛盾就在于需要传输的数据包大小，如果数据包小到一定程度，UDP协议绝对最佳的选择，但是当数据包逐渐增大直到突破512字节以及MTU1500字节的限制时，我们也只能选择使用更可靠的TCP协议来传输DNS查询和相应。

## 其它

假设向服务器请求某个HTML文档到本地，则无论是文档本身还是文档当中所包含的图片，脚本文件，样式文件都必须各自发起一次请求将其取回到本地，由浏览器组织并渲染出页面展示给用户。

HTTP是面向文本的，报文中的每一个字段都是一些ASCII码串，每个字段的长度不确定。

HTTP报文会被封装在TCP报文的数据载荷部分。

Cookie是一种对无状态的HTTP进行状态化的技术。

HTTP的1.1版本支持持续连接方式，当请求头中的connection字段为keep-alive时，表示希望建立持续连接，但如果是close，就表示服务器发送完文档后即可释放连接。
