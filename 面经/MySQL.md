## B树和B+树区别

- 前者在非叶节点也存储数据，后者在非叶节点只存储索引；
- 前者叶节点独立，后者叶节点之间通过指针互相连结。

## InnoDB 锁

## 事务

### 四大特性

- 原子性
- 一致性
- 隔离性
- 持久性

### 并发事务带来的问题

- 脏写(修改丢失)：一个事务修改了另一个未提交事务修改过的数据，另一个事务回滚将导致当前事务的修改丢失，此时发生了脏写；

- 脏读(读“不存在”数据)：一个事务读到了另一个未提交事务修改过的数据，另一个事务回滚将导致当前事务读取到一个不存在的数据，此时发生了脏读；

- 不可重复读(读不一样/少读)：一个事务只能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值，此时发生了不可重复读。

- 幻读(多读)：一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来，此时发生了幻读。
  - 幻读强调的是一个事务按照某个相同条件多次读取记录时，后读取时读到了之前没有读到的记录。对于之前能读取到，后面又读取不到，这种情况应该称为不可重复读。

### 隔离级别

- 读未提交：解决脏写；
- 读已提交：解决脏写、脏读；
- 可重复读：解决脏写、脏读、不可重复读；
- 串行化：解决脏写、脏读、不可重复读、幻读。

## 什么是当前读

通俗点讲，就是在最新的行数据版本上进行读取，比如更新语句，需要先读后写，此时读取到的是数据的历史版本就没有任何意义。另外，如果 SELECT 语句采用的是“锁定读”，同样也是当前读。

## 幻读

在**可重复读**隔离级别下，普通查询是快照读，是看不到其它事务插入的数据的，因此，幻读只在“当前读”下才会出现。

**幻读仅专指“新插入的行”，对于旧的行被修改，然后被读到，这不是幻读**。

产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 Gap Lock。

间隙锁之间是不存在冲突的，和间隙锁冲突的是往这个间隙插入一个记录这个操作。

因此两个事务相同的间隙锁可以反复的加，这就有可能导致死锁。

例如执行 `SELECT * FROM T WHERE d=5 FOR UPDATE;`。

“当前读”执行，此时将当前所有 d=5 的行都加了写锁，但是！其它 d!=5 的行没加锁，其它事务可以将某个 d!=5 的记录改为 d=5，这样下次执行相同语句时，就出现了其它语句，虽然这个不叫作幻读。

还有一种就是直接插入了一条 d=5 的语句，这时候就出现了幻读。

原因就在于该语句加的行锁，只是**静态**地将此时符合条件的行进行加锁，无法动态地阻止其它事务进行操作。

为了阻止第一类情况的发生，最简单的方法就是给所有扫描到的行都加锁，这样就可以阻止其它事务将其它数据修改为符合条件的数据，而阻止第二类情况的发生， 就只能在行与行之间进行加锁，防止出现插入这样的操作。

**间隙锁加行锁的组合被称为 Next-Key Lock**。

## 间隙锁的死锁问题

事务 A、B 先后加了同一个间隙锁，而 B 此时往间隙中插入语句，被 Block，而 A 后续往间隙中插入语句，被 Block，发现死锁，执行失败。

另外间隙锁的引入是会影响并发的。比如数据中存在 5 和 10，查 9 会将 5 到 10 都锁住，那么 6、7、8 都受到了影响。

## 一致性非锁定读

所谓“一致性非锁定读“，实际上是一个借助 Undo Log 所实现的多版本并发控制技术，它可以在在行数据被加写锁的情况下，此时依旧可以读取到数据，目的是为了提高数据库的并发性。

- 读已提交：总是读取被锁定行的最新一份快照数据；
- 可重复读：总是读取事务开始时的行数据版本。

## 索引

### 选错索引

优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的CPU资源越少。

MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。

而统计信息就是索引的“区分度”，区分度就是索引数据的基数，而要得到基数是MySQL通过【抽样统计】的方式获得的。

有时候优化器可能会选择 explain 计划中显示扫描行数更多的，这是因为考虑了回表操作带来的损耗(比起每次都回表，倒不如一开始直接回表)，而扫描行数少的因为预估偏差太过于大，导致考虑了回表操作后没有被优化器选择。

一个做法就是使用 `analyze table...` 命令来重新统计索引信息，让扫描行数准确，影响的权重更大。

对于其它情况，可以使用 `force index...` 强行选择我们认为应该选择的索引，或者尝试修改 SQL 语句语义。

## 日志

- Undo Log：记录的是每个事务中所有更新语句的反向操作，它提供了事务回滚的能力；
- Bin Log：记录的是每一个更新语句，通常用于主从复制时从库进行数据同步，以及将数据恢复到以往的某一时刻。它是追加写，当容量超过一定大小时，会新建文件继续写入，保证所有的历史操作都得到记录，可以起到归档的作用；
- Redo Log：记录的是每个数据页上发生的更新操作（比如将第 0 号表空间的 100 号页面的偏移量为 1000 处的值更新为 2)，它是循环写，即空间有固定大小，因此会出现一些历史记录被覆盖，无法起到归档的作用。

## 更新语句的执行过程

SQL 语句经过连接器、查询缓存、分析器、优化器，在执行器开始执行。

1. 找数据引擎获取符合条件的记录，如果符合条件的记录所在页已经在内存当中，数据引擎将直接返回给执行器，否则引擎从磁盘读入内存，再返回；
2. 执行器拿到引擎给的数据，修改数据内容，再调用数据引擎写入更新后的数据；
3. 引擎将数据**更新到内存**，同时将更新操作记录到 Redo Log，此时 Redo Log 处于【prepare】状态，之后引擎通知执行器执行完成，随时可以提交事务；
4. 执行器生成该操作的 Bin Log，将 Bin Log 写入磁盘（如果此时 crash，由于 Redo Log 处于【prepare】状态，事务无效，回滚数据，回滚后 Bin Log 中相同记录的修改被后续的回滚修改抵消）；
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 Redo Log 改成【commit】状态，更新完成。

### 两阶段提交的目的

**让 Redo Log 和 Bin Log 之间的逻辑一致**。

假设先写其中一个日志后写另一个日志，而不是将 Redo Log 拆分成两次：

1. 先写 Redo Log，再写 Bin Log。写完 Redo Log 后，进程崩溃，此时 Bin Log 未写，内存中的修改丢失。由于 Redo Log 具备 crash-safe 能力，它可以将刚才内存中的更新操作给恢复回来，
