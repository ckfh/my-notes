# 笔记

## MySQL架构

客户端->服务层->引擎层。

服务层包含连接器、查询缓存、分析器、优化器、执行器等，所有跨引擎的功能都在该层实现。

引擎层负责数据的存储和提取。

连接器：负责跟客户端建立连接、获取权限、维持和管理连接。

查询缓存：顾名思义，但是限制非常多。

分析器：对SQL语句进行词法分析和语法分析。

优化器：确定执行计划。

执行器：检查是否有执行权限，没有则返回错误，有权限则开始执行SQL语句。

### 一条查询语句的执行过程

SQL语句经过连接器、查询缓存、分析器、优化器，在执行器开始执行，调用表定义的引擎接口，取表的记录添加到结果集返回给客户端。

### 一条更新语句的执行过程

更新语句和查询语句差不多，但是更新流程涉及两个重要的日志模块：redo log和binlog。

1. **redo log是innodb特有的，binlog是MySQL服务层实现的**，所有引擎都能用。因为innodb支持事务，需要crash-safe能力，所以需要redo log来实现crash-safe能力。
2. redo log是物理日志，记录的是“某个数据页上做了什么修改”，binlog是逻辑日志，记录的是语句的原始逻辑，比如“给ID=2记录的C字段加1”。
3. redo log是循环写，空间固定，会被用完，此时需要先将之前的日志持久化到磁盘，然后再写；binlog是追加写，写到一定大小后会切换到下一个，不会覆盖之前的日志。

切回到执行器，执行流程如下：

1. 先找引擎取ID=2记录，如果ID=2记录所在页本来就在内存中，引擎直接返回给执行器；否则引擎从磁盘读入内存，再返回。
2. 执行器拿到引擎给的数据，修改数据内容，再调用引擎接口写入新数据。
3. 引擎将数据**更新到内存**，同时将更新操作记录到redo log，此时redo log处于【prepare】状态，之后引擎通知执行器执行完成，随时可以提交事务。
4. 执行器生成该操作的binlog，并把binlog写入磁盘。(如果此时crash，由于redo log处于【prepare】状态，事务无效，回滚该数据，回滚后binlog中相同记录的修改被后续修改覆盖回原值)
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成【commit】状态，更新完成！

redo log的两阶段提交目的：让redo log和binlog之间的逻辑一致。

假设不用两阶段提交会出现什么情况？比如先写某个日志再写另一个，而不是将一个redo log拆开来。

1. 先写redo log再写binlog。假设redo log写完，binlog没写完系统崩溃，MySQL进程异常重启，内存数据丢失，由于redo log具备崩溃恢复能力，因此能够将原始库ID=2记录数据给恢复回来。但是binlog没有记录该语句，之后备份日志的时候，binlog就没有该语句。如果用这个binlog来恢复临时库的话，临时库就少了这次更新，恢复出来的值少了该更新语句，与原始库的值不同。
2. 先写binlog再写redo log。binlog写完后crash，由于redo log没写，崩溃恢复后该事务被视为无效，原始库ID=2记录应仍为原始值，但是binlog已经记录了，备份的时候就多了一个事务出来，又和原始库的值不一致。

## 主键和唯一键

主键每张表唯一，唯一键不一定，多个字段都允许设置为唯一键，表示该字段不允许有重复值。主键不一定包含一个字段，可以由多个字段确定主键。

## 慢SQL原因

一条SQL执行得很慢的原因：

1. 大多数情况正常，偶尔很慢：数据库在刷新脏页，例如redo log满了要写磁盘；执行时遇到了锁。
2. 一直很慢：没有用上索引，导致全表扫描，索引设置得不正确。

## 慢查询性能问题

1. 索引没有设计好。
    - 紧急创建索引，5.6版本后支持online ddl，对于高峰期数据库被该语句打挂的问题，最有效做法是执行alter table语句。
    - 比较理想的是，在备库先执行，然后切换，在主库也执行。
2. SQL语句没写好。
    - 比如把索引放在了运算式中导致逻辑相同的语句索引失效，办法就是改写该语句。
3. MySQL选错了索引。
    - 紧急方案就是用`force index`强制使用指定索引。

## B树和B+树

在B树上面进行数据查找，如果不考虑任何形式的优化，每次都需要从根节点开始向下查询，这个过程中会造成大量的随机I/O。

随机I/O指的是读取逻辑上连续的数据，而数据被存放在非连续的内存地址中。

比如一个范围查询的数据刚好在根节点和其左右节点内，那么查找的顺序为：

1. 随机I/O加载根节点，找到左孩子指针。
2. 随机I/O加载左节点，找到指定数据。
3. 随机I/O加载根节点，找到指定数据以及右孩子指针。
4. 随机I/O加载右节点，找到指定数据。

这是因为B树在非叶节点上也存放有数据，导致进行数据查找时只能按照这样的方式进行。

而B+树在访问范围数据时，先是通过根节点一直向下找到叶节点，即使需要跨叶节点，也可以直接通过连接指针快速查找到相邻节点，不需要再从根节点出发找到相邻节点。

B+树优势：

1. 哈希虽然能够提供O(1)的单数据行操作性能，但是对于范围查询和排序却无法很好地支持，最终导致全表扫描；
2. B树能够在非叶节点中存储数据，但是这也导致在查询连续数据时可能会带来更多的随机I/O，而B+树的所有叶节点可以通过指针相互连接，能够减少顺序遍历时产生的额外随机I/O；

B树和B+树区别：

1. B树的所有节点既存放键(key)也存放数据(data);而B+树只有叶子节点存放key和data，其它内节点只存放key。
2. B树的叶子节点都是独立的；B+树的叶子节点有一条引用链指向与它相邻的叶子节点。
3. B树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。

### 为什么选择B+树

使用二叉树：可能退化为链表，导致查找时间复杂度为O(n)。

使用AVL树：为了追求绝对平衡，其旋转操作十分耗时。

使用红黑树：比起AVL树更好一些，但是一个节点只能存储一份数据，数据量大时，将导致红黑树高度增大，此时时间复杂度也会变大。

使用B树：由于非叶节点和叶节点都存有数据，多次取出数据的时间不稳定，进行范围查询时，如果需要跨节点，每次都需要从上至下遍历。

使用B+树：数据都存在叶子节点，取出数据的时间稳定，进行范围查询时，如果需要跨节点，可通过叶节点之间的指针依次向后遍历即可。

## 索引

建立索引的代价：

1. 空间上的代价：一个索引对应一颗B+树，一颗B+树的每一个节点都是一个数据页，一个页默认占用16KB大小的存储空间。
2. 时间上的代价：对数据进行更新时，都需要修改各个B+树的索引(需按照顺序排序节点)，需要额外的时间进行记录移位，页面分裂，页面回收等操作，降低性能。

聚簇索引：

1. 使用记录主键值的大小进行记录和页的排序
    - 页内的记录是按照主键的大小顺序排成一个单向链表。
    - 各个存放用户记录的页也是根据页中用户记录的主键大小顺序排成一个双向链表。
    - 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个双向链表。
2. 叶子节点存储的是完整的用户记录

非聚簇索引：

1. 使用记录c2列的大小进行记录和页的排序
2. 叶子节点存储的并不是完整的用户记录，而只是c2列+主键这两个列的值
3. 目录项记录中不再是主键+页号的搭配，而变成了c2列+页号的搭配

B+树的叶节点即数据节点存放的数据是升序排序的，这样的好处是可以用二分查找快速定位到指定区域，如果数据无序，则二分查找无法施展效果。

因此假设索引为(name, age, number)，进行条件查询where name = ? and number = ?，一开始name有序，可以利用二分查找快速找出和name相等的记录，比如说定位到最左索引，然后从最左索引沿着链表往右找，name相同的记录中又是按照age进行排序的，而想要利用二分查找找到和number相等的记录前提是保证age是相同的。

也就是说name相同，age有序，age有序不代表number有序。

必须是name相同，age相同，此时number才有序，才能进行二分查找。

因此where name = ? and number = ?，只用到了name的索引，age和number索引都没有用到，必须要进行一次遍历找出所有number相等的记录。

如果排序用到了索引列，那是最好的，因为这样就不需要将所有的数据从磁盘加载到内存，然后排序，再返回给客户端。

索引既然已经有序了，就不需要再进行排序，直接回表操作返回数据即可。

因此排序用到索引的关键是返回数据前不需要进行排序。

排序索引还有个点是排序方向要一致，不要混用会直接进行文件排序，这是MySQL规定的。

访问二级索引时是顺序I/O，因为二级索引都是有序的，但是根据二级索引查出来的ID不一定有序，因此回表到聚簇索引时，使用的是随机I/O。顺序I/O比起随机I/O来说要更快。

但是如果说需要回表的记录非常多，使用二级索引的性能就不是很高，宁愿直接在聚簇索引上直接全表扫描，也不愿意使用二级索引再回表。

查询优化器会记录查询的记录数量，如果数量越多，越倾向于直接全表，数量越少，则二级+回表。

为了彻底回避回表带来的性能损耗，建议在查询列中只包含索引列，这样直接在二级索引上就可以获得数据，不需要回表。

这种只用到索引的查询称为索引覆盖。

1. 为搜索、排序、分组的列创建索引。
2. 为基数大的列建立索引，太小的列建立索引效果可能不好，基数指的是列中数据非重复程度。
3. 索引列的类型尽量小，这样一个索引数据页就可以存储更多的数据，减少IO的次数。
4. 只有索引列在比较表达式中单独出现才可以适用索引。

### 普通索引和唯一索引

在业务可以保证唯一性的情况下，来讨论这两个索引才有意义，如果可以更推荐普通索引，首先两者在查询上的性能几乎微乎其微，只不过普通索引会多进行几次判断，而在更新上，普通索引配合change buffer性能会更明显，**主要是当要更新的记录不在内存时**，唯一索引需要将数据页读入内存才能**确定数据是否唯一**，而普通索引只要将更新记录到change buffer中，语句执行就结束了。

### 对字符串字段创建索引的方式

1. 直接创建完整索引，但是比较占用空间；
2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
4. 创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式类似，不支持范围扫描。

### 索引合并优化

简单来说就是，一条SQL语句中使用多个索引时，查询出来的数据取交集或并集。

OR语句求并集，比如执行`SELECT * FROM table WHERE a='xxx' OR b='xxx'`时，如果a和b上都有各自的索引，可以按照两个索引进行查询，最后对结果进行union操作。

AND语句求交集，比如执行`SELECT * FROM table WHERE a='xxx' AND b='xxx'`时，如果a和b上都有各自的索引，可以按照两个索引进行查询，最后对结果进行intersect操作。

索引合并不一定能提高效率，比如索引a查询100W条，索引b查询100条，两者取交集时，还是比较消耗IO性能的。

## 事务

什么是事务：

需要保证原子性、隔离性、一致性和持久性的一个或多个数据库操作称之为一个事务。

1. 要么全做，要么全不做的规则称之为原子性。
2. 不仅要保证这些操作以原子性的方式执行完成，而且要保证其它客户端的状态转换不会影响到本次状态转换，这个规则被称之为隔离性。
3. 如果数据库中的数据全部符合现实世界中的约束（all defined rules），我们说这些数据就是一致的，或者说符合一致性的。
4. 当把现实世界的状态转换映射到数据库世界时，持久性意味着该转换对应的数据库操作所修改的数据都应该在磁盘上保留下来，不论之后发生了什么事故，本次转换造成的影响都不应该被丢失掉.
    - 因为引擎在向磁盘进行数据变更时，是预先进行缓存的，不是每一次请求都会进行一次磁盘I/O，不然性能会大大降低。
    - 既然有缓存，那就需要考虑服务宕机时未写往磁盘的缓存丢失了，那些数据怎么办。

### 事务并发的问题

- 脏写：一个事务修改了另一个未提交事务修改过的数据，另一个事务回滚将导致当前事务的修改丢失，此时发生了脏写。
- 脏读：一个事务读到了另一个未提交事务修改过的数据，另一个事务回滚将导致当前事务读取到一个不存在的数据，此时发生了脏读。
- 不可重复读：一个事务只能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值，此时发生了不可重复读。
- 幻读：一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来，此时发生了幻读，**幻读强调的是一个事务按照某个相同条件多次读取记录时，后读取时读到了之前没有读到的记录。对于之前能读取到，后面又读取不到，这种情况应该称为不可重复读**。

严重性：脏写 > 脏读 > 不可重复读 > 幻读 ==> 修改丢失 > 读取不存在数据 > 读不一致，少读 > 多读。

### 事务的隔离级别

设立一些事务隔离级别，来防止上述问题的发生，级别越低，越严重的问题可能发生。

- 未提交读：脏读、不可重复读、幻读
- 已提交读：不可重复读、幻读
- (MySQL默认)可重复读：幻读
- 可串行化

无论那种隔离级别都不允许脏写发生。

## MVCC

在实现上，数据库里面会创建一个视图，事务访问数据的时候以视图的逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；而“串行化”隔离级别下直接用加锁的方式来避免并行访问。

## 日志

### binlog

记录数据库更新操作的二进制日志。

适用于主从复制和数据恢复。

binlog有三种模式：

1. ROW模式，日志会记录每个被更新行。优点：不记录SQL语句的上下文，日志里能清楚地知道每个行的内容。缺点：日志容量非常大，主从复制时磁盘I/O消耗大。
2. STATEMENT模式，每一条更新的SQL语句都会记录在日志里。优点：不需要记录每个更新行，减少日志量，节约I/O，提高性能。缺点：为了保证一条更新SQL语句在slave上的正常运行，还需要额外记录一些上下文内容，并且一些函数功能，在master和slave上要保持一致会有许多相关问题。
3. MIXED模式：一般的语句修改用STATEMENT格式记录SQL语句，一些无法完成主从复制的函数，采用ROW格式记录更新行，MySQL会自己根据每一条具体的SQL语句来确定需要记录的日志格式。

### redolog

适用于崩溃恢复，innodb独有。

### undolog

原子性保证的底层实现。

## 主从复制

[参考](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/mysql-read-write-separation.md)

本质上就是从库从主库中拷贝binlog，写入到自己的一个名叫relay log(中继日志)中，中继日志这个名字一听就知道是从库先进行拷贝工作，然后”串行“执行relay log中的记录，因此才有”中继“这一说，不是一边拷贝一边执行，而是全部拷贝完毕才开始执行。

由于从库是”串行“执行中继日志中的记录内容，因此从库和主库实际上会有数据延时，通常主库上的写，在从库上会有几十到几百毫秒才能读取到变化的内容。

主从复制的一个问题是：主库忽然宕机，恰好从库的数据只同步了新内容的一半，因此会有部分数据从库上是没有的。

1. 半同步复制，指的就是主库写入binlog日志之后，就会强制将数据同步到从库，从库将日志写入自己本地的relay log之后，接着会返回一个ACK给主库，主库接收到至少一个从库的ACK之后才会认为写操作完成了。
2. 并行复制，指的是从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。

## 分库分表

为什么分库？为了降低单个库的并发请求数量，并且降低了每个库的磁盘使用情况。

为什么分表？为了提高SQL语句的执行效率。

水平拆分：就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。

垂直拆分：就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。把一个大表拆开，订单表、订单支付表、订单商品表。
