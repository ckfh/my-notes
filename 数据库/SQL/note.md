# 笔记

## 实践

### SQL Server索引实践

1. 根据查询列建立非聚集索引。
2. 如果不需要回表找到所有数据，可以往非聚集索引中添加包含列，即往非聚集索引的节点中添加额外的列数据，但是这些列数据并不参与索引。
3. 通过建立临时表存储一次计算的结果，之后进行二次计算时，就不需要再进行一次计算，直接在临时表上进行二次计算。

## 主键和唯一键

主键每张表唯一，唯一键不一定，多个字段都允许设置为唯一键，表示该字段不允许有重复值。主键不一定包含一个字段，可以由多个字段确定主键。

## 慢SQL原因

一个SQL执行得很慢，分析原因：

1. 大多数情况正常，偶尔很慢：数据库在刷新脏页，例如redo log满了要写磁盘；执行时遇到了锁。
2. 一直很慢，没有用上索引，导致全表扫描，索引设置得不正确。

## B树和B+树

在B树上面进行数据查找，如果不考虑任何形式的优化，每次都需要从根节点开始向下查询，这个过程中会造成大量的随机I/O。

随机I/O指的是读取逻辑上连续的数据被存放在非连续的内存地址中。

比如一个范围查询的数据刚好在根节点和其左右节点内，那么查找的顺序为：

1. 随机I/O加载根节点，找到左孩子指针。
2. 随机I/O加载左节点，找到指定数据。
3. 随机I/O加载根节点，找到指定数据以及右孩子指针。
4. 随机I/O加载右节点，找到指定数据。

这是因为B树在非叶节点上也存放有数据，导致进行数据查找时只能按照这样的方式进行。

而B+树在访问范围数据时，先是通过根节点一直向下找到叶节点，即使需要跨叶节点，也可以直接通过连接指针快速查找到相邻节点，不需要再从根节点出发找到相邻节点。

B+树优势：

1. 哈希虽然能够提供O(1)的单数据行操作性能，但是对于范围查询和排序却无法很好地支持，最终导致全表扫描；
2. B树能够在非叶节点中存储数据，但是这也导致在查询连续数据时可能会带来更多的随机I/O，而B+树的所有叶节点可以通过指针相互连接，能够减少顺序遍历时产生的额外随机I/O；

B树和B+树区别：

1. B树的所有节点既存放键(key)也存放数据(data);而B+树只有叶子节点存放key和data，其它内节点只存放key。
2. B树的叶子节点都是独立的；B+树的叶子节点有一条引用链指向与它相邻的叶子节点。
3. B树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。

## 索引

建立索引的代价：

1. 空间上的代价：一个索引对应一颗B+树，一颗B+树的每一个节点都是一个数据页，一个页默认占用16KB大小的存储空间。
2. 时间上的代价：对数据进行更新时，都需要修改各个B+树的索引(需按照顺序排序节点)，需要额外的时间进行记录移位，页面分裂，页面回收等操作，降低性能。

聚簇索引：

1. 使用记录主键值的大小进行记录和页的排序
    - 页内的记录是按照主键的大小顺序排成一个单向链表。
    - 各个存放用户记录的页也是根据页中用户记录的主键大小顺序排成一个双向链表。
    - 存放目录项记录的页分为不同的层次，在同一层次中的页也是根据页中目录项记录的主键大小顺序排成一个双向链表。
2. 叶子节点存储的是完整的用户记录

非聚簇索引：

1. 使用记录c2列的大小进行记录和页的排序
2. 叶子节点存储的并不是完整的用户记录，而只是c2列+主键这两个列的值
3. 目录项记录中不再是主键+页号的搭配，而变成了c2列+页号的搭配

B+树的叶节点即数据节点存放的数据是升序排序的，这样的好处是可以用二分查找快速定位到指定区域，如果数据无序，则二分查找无法施展效果。

因此假设索引为(name, age, number)，进行条件查询where name = ? and number = ?，一开始name有序，可以利用二分查找快速找出和name相等的记录，比如说定位到最左索引，然后从最左索引沿着链表往右找，name相同的记录中又是按照age进行排序的，而想要利用二分查找找到和number相等的记录前提是保证age是相同的。

也就是说name相同，age有序，age有序不代表number有序。

必须是name相同，age相同，此时number才有序，才能进行二分查找。

因此where name = ? and number = ?，只用到了name的索引，age和number索引都没有用到，必须要进行一次遍历找出所有number相等的记录。

如果排序用到了索引列，那是最好的，因为这样就不需要将所有的数据从磁盘加载到内存，然后排序，再返回给客户端。

索引既然已经有序了，就不需要再进行排序，直接回表操作返回数据即可。

因此排序用到索引的关键是返回数据前不需要进行排序。

排序索引还有个点是排序方向要一致，不要混用会直接进行文件排序，这是MySQL规定的。

访问二级索引时是顺序I/O，因为二级索引都是有序的，但是根据二级索引查出来的ID不一定有序，因此回表到聚簇索引时，使用的是随机I/O。顺序I/O比起随机I/O来说要更快。

但是如果说需要回表的记录非常多，使用二级索引的性能就不是很高，宁愿直接在聚簇索引上直接全表扫描，也不愿意使用二级索引再回表。

查询优化器会记录查询的记录数量，如果数量越多，越倾向于直接全表，数量越少，则二级+回表。

为了彻底回避回表带来的性能损耗，建议在查询列中只包含索引列，这样直接在二级索引上就可以获得数据，不需要回表。

这种只用到索引的查询称为索引覆盖。

1. 为搜索、排序、分组的列创建索引。
2. 为基数大的列建立索引，太小的列建立索引效果可能不好，基数指的是列中数据非重复程度。
3. 索引列的类型尽量小，这样一个索引数据页就可以存储更多的数据，减少IO的次数。
4. 只有索引列在比较表达式中单独出现才可以适用索引。

## 事务

什么是事务：

需要保证原子性、隔离性、一致性和持久性的一个或多个数据库操作称之为一个事务。

1. 要么全做，要么全不做的规则称之为原子性。
2. 不仅要保证这些操作以原子性的方式执行完成，而且要保证其它的状态转换不会影响到本次状态转换，这个规则被称之为隔离性。
3. 如果数据库中的数据全部符合现实世界中的约束（all defined rules），我们说这些数据就是一致的，或者说符合一致性的。
4. 当把现实世界的状态转换映射到数据库世界时，持久性意味着该转换对应的数据库操作所修改的数据都应该在磁盘上保留下来，不论之后发生了什么事故，本次转换造成的影响都不应该被丢失掉.

### 事务并发的问题

- 脏写：一个事务修改了另一个未提交事务修改过的数据，另一个事务回滚将导致当前事务的修改丢失，此时发生了脏写。
- 脏读：一个事务读到了另一个未提交事务修改过的数据，另一个事务回滚将导致当前事务读取到一个不存在的数据，此时发生了脏读。
- 不可重复读：一个事务只能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值，此时发生了不可重复读。
- 幻读：一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来，此时发生了幻读，**幻读强调的是一个事务按照某个相同条件多次读取记录时，后读取时读到了之前没有读到的记录。对于之前能读取到，后面又读取不到，这种情况应该称为不可重复读**。

严重性：脏写 > 脏读 > 不可重复读 > 幻读 ==> 修改丢失 > 读取不存在数据 > 读不一致，少读 > 多读。

### 事务的隔离级别

设立一些事务隔离级别，来防止上述问题的发生，级别越低，越严重的问题可能发生。

- 未提交读：脏读、不可重复读、幻读
- 已提交读：不可重复读、幻读
- (MySQL默认)可重复读：幻读
- 可串行化

无论那种隔离级别都不允许脏写发生。

## MVCC

## 日志

### binlog

记录数据库更新操作，不记录查询操作的二进制日志。

作用于数据恢复。

binglog有三种模式：

1. ROW模式，日志会记录每个被更新行。优点：不记录SQL语句的上下文，日志里能清楚地知道每个行的内容。缺点：日志容量非常大，主从复制时磁盘I/O消耗大。
2. STATEMENT模式，每一条更新的SQL语句都会记录在日志里。优点：不需要记录每个更新行，减少日志量，节约I/O，提高性能。缺点：为了保证一条更新SQL语句在slave上的正常运行，还需要额外记录一些上下文内容，并且一些函数功能，在master和slave上要保持一致会有许多相关问题。
3. MIXED模式：一般的语句修改用STATEMENT格式记录SQL语句，一些无法完成主从复制的函数，采用ROW格式记录更新行，MySQL会自己根据每一条具体的SQL语句来确定需要记录的日志格式。

## 主从复制

[参考](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/mysql-read-write-separation.md)

本质上就是从库从主库中拷贝binlog，写入到自己的一个名叫relay log(中继日志)中，中继日志这个名字一听就知道是从库先进行拷贝工作，然后”串行“执行relay log中的记录，因此才有”中继“这一说，不是一边拷贝一边执行，而是全部拷贝完毕才开始执行。

由于从库是”串行“执行中继日志中的记录内容，因此从库和主库实际上会有数据延时，通常主库上的写，在从库上会有几十到几百毫秒才能读取到变化的内容。

主从复制的一个问题是：主库忽然宕机，恰好从库的数据只同步了新内容的一半，因此会有部分数据从库上是没有的。

1. 半同步复制，指的就是主库写入binlog日志之后，就会强制将数据同步到从库，从库将日志写入自己本地的relay log之后，接着会返回一个ACK给主库，主库接收到至少一个从库的ACK之后才会认为写操作完成了。
2. 并行复制，指的是从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。

## 分库分表

为什么分库？为了降低单个库的并发请求数量，并且降低了每个库的磁盘使用情况。

为什么分表？为了提高SQL语句的执行效率。

水平拆分：就是把一个表的数据给弄到多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的库里，然后用多个库来扛更高的并发，还有就是用多个库的存储容量来进行扩容。

垂直拆分：就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。把一个大表拆开，订单表、订单支付表、订单商品表。
