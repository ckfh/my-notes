# 黑马笔记

## 安装和启动步骤

推荐在root权限下进行操作：

- 安装gcc和make
- 下载压缩包并解压，在解压目录中使用make，然后make install，默认安装到/usr/local/bin/目录中
- (可选)从解压目录中复制一份redis.conf配置文件到/etc/目录下，并修改其中的daemon值为yes
- 在安装目录中使用redis-server /etc/redis.conf命令启动redis服务端
- 如果要关闭服务端，可以直接在redis客户端命令行中输入shutdown，或者直接在Linux命令行中输入kill -9 pid来关闭
- 查看redis服务端进程号，可以使用命令ps -ef | grep redis来查看

## 命令汇总

- select dbid 切换数据库，默认使用0号数据库，共有16个数据库
- dbsize 查看当前库的key数量
- flushdb/flushall 清空当前库/所有库
- keys * 查看库中所有key
- exists key 查看key是否存在
- type key 查看key类型
- del key 删除key
- unlink key 根据value选择非阻塞删除，仅将key从keyspace元数据中删除，真正删除会在后续的异步操作中
- expire key 10 为指定key设置10s的过期时间
- ttl key 查看key的剩余过期时间，-1表示永不过期，-2表示已过期

## redis模型

IO多路复用+单线程实现类似时分多路复用的方式来支持多客户端并发请求

## 常用五大数据类型

- string
- list
- set
- hash
- zset

## 原子操作

所谓原子操作是不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会发生上下文切换。

1. 单线程中，能够在单条指令中完成的操作都可以认为是“原子操作”，因为中断只能发生在指令之间。
2. 在多线程中，不能被其它进程(线程)打断的操作就叫原子操作。

redis单命令的原子性得益于redis的单线程。

## string

- set
- get
- append
- strlen
- setnx
- incr
- decr
- incrby
- decrby
- mset
- mget
- msetnx
- getrange
- setrange
- setex
- getset

### string底层数据结构-SDS

可以修改的字符串，结构类似Java的ArrayList，采用预分配冗余空间的方式减少内存的频繁分配。

当前字符串实际分配空间capacity一般要高于实际字符串长度len。

当字符串容量小于1M时，扩容都是加倍，如果超过1M，扩容只会多扩1M的空间，最大容量为512M。

## list

- lpush/rpush
- lpop/rpop
- rpoplpush
- lrange
- lindex
- llen
- linsert
- lrem
- lset

### list底层数据结构-quicklist

列表元素较少时会使用一块连续的内存存储，结构是ziplist。

当数据量较多时才改成quicklist，把多个ziplist用双向指针的链表形式组成quicklist。

如果一开始就是用普通的链表形式进行存储，会造成空间上的浪费，因为一个链表元素除了存放类型数据外，还要存放两个额外的指针。

## set

- sadd
- smembers
- sismember
- scard
- srem
- spop
- srandmember
- smove
- sinter
- sunion
- sdiff

### set底层数据结构-字典

类似于Java的hashset，内部实现用的是hashmap，让所有的value指向同一个对象。

这里使用hash结构，所有的value指向同一个内部值。

## hash

- hset
- hget
- hmset
- hexists
- hkeys
- hvals
- hincrby
- hsetnx

### hash底层数据结构-ziplist和hashtable

当field-value长度短且个数少时，使用ziplist，否则使用hashtable。

## 存储对象的几种方式

对象：{id=1,name=zhangsan,age=20}。

1. 序列化字符串并存储，user -> {id=1,name=zhangsan,age=20}，缺点是修改值需要整个取出修改再放入。
2. 每个属性分开存放，user:id -> 1/user:name -> zhangsan/user:age -> 20，缺点是数据太分散。
3. 利用hash结构进行存放，user -> (id -> 1/name -> zhangsan/age -> 20)

## zset

- zadd
- zrange
- zrangebysocre
- zrevrangebyscore
- zincrby
- zrem
- zcount
- zrank

利用zset实现一个文章访问量排行榜的功能：将访问量作为score，文章题目作为member。

### zset底层数据结构

一方面它等价于Java的Ma`p<String, Double>`数据结构，可以给每个member赋予一个权重score，另一方面它又类似于TreeSet，内部元素会按照score进行排序。

使用到了两种数据结构：

1. hash，hash作用就是关联member和score，保证member唯一性，并且通过member找到score。
2. 跳表，跳表目的在于给member排序，以及进行范围获取。

## 有序集合

有序集合的实现可以用数组、平衡树、链表等。数组不便插入和删除，平衡树或红黑树虽然效率高但结构复杂，链表查询效率低，跳表效率堪比红黑树，且实现远比红黑树简单。

跳表和B+树对于范围查询的支持是非常高效的，可以直接通过一个元素的指针找到下一个元素，不需要像B树和红黑树那样每次都从头节点出发找到相邻的下一个元素。

Redis使用跳表的原因可能是B/B+树更适合大容量数据的I/O，它每个节点可以存储多个元素内容，并且树的层数非常低。

Redis毕竟是面向内存存储的一种数据结构，不需要实现B+树这种复杂结构，用跳表就可以满足要求了。

跳表查找元素过程：从最高层开始，逐个比较元素大小，如果元素耗尽或者元素值在两者之间，则进入到下一层。

## 配置文件

```text
network；
bind 127.0.0.1 -::1 表示仅支持本机访问，可以选择将其注释，允许远程访问。
protected-mode yes 保护模式，开启本机保护模式，将其值修改为no，允许它机访问。
tcp-backlog 511 全连接队列大小，高并发模式下需要调大该参数以便支持更高的并发量。
timeout 0 一个客户端两次操作之间的超时关闭机制，0表示禁用该功能
tcp-keepalive 300 TCP保活机制，客户端连接后但未进行任何操作，需要发送心跳包进行探测。
插一句：连接建立和连接可用是两种不同的概念，在网络传输中，两个主机之间连接建立后，可能由于服务端满载、假死，导致连接此时不可用，但是连接此时仍处于建立状态，因此需要另一种机制来对连接的可用性进行探测。
general；
pidfile /var/run/redis_6379.pid 将redis-server启动时所分配的进程号写入到该文件中。
loglevel notice 日志级别，debug、verbose、notice、warning
logfile "" 设置日志输出目录
```

## 发布和订阅-一种消息通信方式

```text
client subscribe channel
server publish channel
```

## bitmaps

- setbit
- getbit
- bitcount
- bitop

求集合中不重复元素个数的问题称为基数问题。

## hyperloglog

- pfadd
- pfcount
- pfmerge

## geospatial

- geoadd
- geoposs
- geodist
- georadius

## 事务

**和数据库事务是完全不同的概念，虽然都叫事务**。

redis事务是一个单独的隔离操作：事务中所有命令都会序列化、按顺序地执行。

事务在执行过程中，不会被其它客户端发送来的命令请求打断。

redis事务的主要作用就是“串联多个命令”防止别的命令插队。

multi 命令1入队、命令2入队、命令3入队 exec 执行命令1、执行命令2、执行命令3。

入队过程中可以使用discard放弃本次事务。

### 事务错误处理

1. 入队时，因为命令语法问题导致命令输入失败，则后续exec时会直接放弃该事务。
2. 执行时，因为命令操作问题导致命令失败，则该命令将不会执行，其它命令正常执行。

### 事务冲突(多个事务之间操作共享资源)处理

乐观锁：

redis基于check-and-set机制实现乐观锁机制。

在multi之前，先执行watch某个或多个key，在事务exec时，如果这些key被其它命令改动，那么事务将被打断。

借助于类似版本号的机制，如果set时的版本号和watch时的版本号不一致，则本次修改失败。

### redis事务三特性

1. 单独的隔离操作；
2. 因为是单独的隔离操作，因此没有隔离级别的概念；
3. 不保证原子性。

### redis事务再解析

[参考](https://blog.csdn.net/qq_35102066/article/details/103207283)

为什么单线程模型的redis仍会有事务并发问题，进而借助了乐观锁机制来解决该问题。

首先redis对于多个客户端连接采用的是IO多路复用加单线程进行处理的，由selector将客户端请求交由后面的单线程执行。

**实际上并发问题是从客户端的角度出发而出现的**，具体可参考上述链接文章中的例子，本质上是因为客户端的多个命令没有放到一个事务当中执行导致的并发问题。

比如两个客户端同时请求商品数目为一的一个商品，并对商品数目进行减一，但是出现了如下情况：A客户端请求数目为一/B客户端请求数目为一/B客户端数目减一/A客户端数目减一，就是因为“请求”和“扣除”操作不是连续执行的。

要解决这种情况首先必须使用事务来保证命令被连续执行，不被打断，并且需要使用watch命令提供的乐观锁机制来保证共享资源状态的正确性，后执行的事务发现指定key的值发生改变，就会放弃当前事务的执行。

为什么pipeline不能代替事务，它也可以打包指令，并且不需要借助multi和exec两个额外指令。

pipeline是将要发送的命令先存储在客户端，等到要发送时将所有命令打包一起发送给服务端，这是因为缓冲区机制的缘故。

而服务端在接收到multi指令时，不会立即执行后续指令，而是将所有指令都入队，直到接收到exec指令才执行。

由于存在缓冲区，pipeline无法保证多条命令是被一起发送还是分开发送，而命令一旦到达服务端将会被立即执行，因此无法保证原子性。

而即便存在缓冲区，对于事务来说，多条指令被分开发送也不会受到影响，因为服务端必须等到exec命令后才会执行所有命令。

还有一点要说明的是，服务端自身也存在缓冲区，你即便多条指令是被一起发送，但是服务端read操作不能每次都将缓冲区中的数据都读取出来(如果使用的epoll的边缘触发则可以)，能读多少只有内核知道。

## 秒杀案例

秒杀成功，商品库存减一，将用户ID加入到该商品对应的秒杀成功者集合中。

### 客户端出现连接超时问题

连接超时是因为redis所能承受的最大并发量有限，因此部分客户端的连接会暂时无法进行请求操作，使用连接池解决。

### 服务端出现超卖问题(库存数量为负数，正常为零)

超卖是因为多个操作之间没有考虑共享资源状态正确性的问题，借助乐观锁和事务可以解决该问题。

### 服务端出现库存遗留问题(库存数量为正数，正常为零)

库存遗留是因为使用了乐观锁机制，只有1个操作成功，其它操作全部失败，失败后也没有后继操作。

比如，2000个请求同时打到服务端，因为乐观锁机制只有1个请求能够修改库存数目成功，剩下的1999个请求则全部失败，此次秒杀活动结束，这就出现了明明有库存，但是大家操作都已经结束了的情况。

LUA脚本解决库存遗留问题。

可以将复杂的或者多步的redis操作，写为一个脚本，一次提交给redis执行，减少反复连接redis的次数，提升性能。

LUA脚本类似redis事务，有一定原子性，不会被其它命令插队，可以完成一些redis事务性的操作。

每个客户端都提交类似这样的一个脚本至服务端：

1. 如果用户已存在集合中，返回2表示已秒杀。
2. 如果库存数量小于等于零，返回0表示秒杀结束。
3. 否则执行库存减一和集合添加操作，返回1表示秒杀成功。

当多个脚本请求到达时，服务端会依次执行，既解决了超卖还解决了遗留问题。

## RDB

在指定时间间隔内将内存中的数据集快照写入磁盘，数据恢复就是将快照文件读回内存里。

### 配置文件中RDB相关

```text
snapshotting;
dbfilename dump.rdb RDB文件名称。
dir ./ RDB文件路径，从哪里启动服务端，就在哪里生成RDB文件。
#   * After 3600 seconds (an hour) if at least 1 key changed        // 一小时内1个key改变则启动持久化
#   * After 300 seconds (5 minutes) if at least 100 keys changed // 5分钟内100key改变则启动持久化
#   * After 60 seconds if at least 10000 keys changed                  // 1分钟内10000key改变则启动持久化
也就是说一定时间内key改变的个数越多，持久化的间隔越短。
并且每次持久化的数据量就是触发持久化的key数量，假设5分钟内有150个key被改变，那么只有前100个key会先被持久化，剩下的50个key则等到下一次持久化。
stop-writes-on-bgsave-error yes 磁盘满时，停止redis的写入操作
rdbcompression yes 设置快照文件是否压缩，压缩会使用LZF算法，如果不想消耗CPU来运行压缩算法的话，可以关闭此功能。
rdbchecksum yes 在持久化之前对数据使用CRC64算法进行数据校验，校验成功后再进行持久化，但是会有10%的性能损耗。
```

### RDB持久化是如何进行的

redis会单独fork一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，主进程是不进行任何IO操作的，这就确保了极高的性能。

不直接写原始文件的主要原因是防止服务端挂掉时写入到一半的操作造成了文件的损坏而无法进行恢复。

如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。

### 为什么最后一次持久化数据可能丢失

可以从上述每次触发持久化操作时key数量的数据去考虑，如果剩下的key在等待数量满足时，服务端忽然挂掉，那么这部分的数据就丢失了。

## AOF

以日志的形式记录每个写操作(增量保存)，只允许追加写日志文件，而数据恢复就是将所有的写操作依次执行一遍。

如果AOF和RDB文件同时存在，则默认使用AOF文件进行数据恢复，因为AOF数据不会存在丢失情况。

如果遇到AOF文件损坏，可通过/usr/local/bin/redis-check-aof appendonly.aof对文件进行修复。

其实AOF文件内容就是依照redis通信协议而组织的，修复过程就是将不符合协议语法的内容给删除掉。

### 同步频率配置

- appendfsync always      始终同步
- appendfsync everysec    每秒同步
- appendfsync no          同步时机交给操作系统

### rewrite压缩

AOF采用文件追加方式，文件会越来越大，为避免出现此种情况，新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。可以使用命令bgrewriteaof。

比如说有如下指令被执行：set a1 v1/set b2 v2/set a1 v3 b2 v4，那很明显只要保留最后一条指令就能完成数据恢复了。

这个重写机制与RDBfork子进程然后写临时文件替换原始文件流程一致。

## 持久化建议

- 官方推荐两个都启用；
- 如果对数据不敏感，单独用RDB。
- 不建议单独用AOF，因为可能有潜在BUG。
- 如果只是纯内存缓存，可以都不用。

## 主从复制

目的：读写分离、容灾恢复。

### 搭建一主多从

1. 创建/myredis文件夹
2. 复制/etc/redis.conf配置文件到文件夹中，开启daemonize，关闭appendonly
3. 配置一主两从，创建三个配置文件
    - redis6379.conf
    - redis6380.conf
    - redis6381.conf
4. 在三个配置文件写入内容(端口名称和文件名一致)
    - include /myredis/redis.conf
    - pidfile /var/run/redis_6379.pid
    - port 6379
    - dbfilename dump6379.rdb
5. 启动三个redis服务
    - info replication 查看当前的主从情况
    - 在从机上执行slaveof ip port进行主从配置

### 主从复制原理

1. slave连上master后，发送数据同步消息(slave主动)。
2. master收到数据同步消息后，把当前数据进行持久化，把rdb文件发给slave，slave根据rdb文件进行数据恢复(全量复制)。
3. 每次master进行写操作后，会和slave进行数据同步操作(master主动、增量复制)。

### 一主二仆

如果slave挂掉，重启后仍为master，需要重新使用slaveof命令进行从机配置，重连后会完成一次全量复制。

如果master挂掉，则slave仍为slave状态，当master重启后，主从配置恢复。

### 薪火相传

若让master直接管理多个slave，当slave数据增大时，数据同步过程会拖累master的性能。

因此让多个slave本身按照层级继续划分，master管理部分slave，而这些slave又管理其它slave。

缺点就是如果一个slave挂掉，那么其管理的slave就得不到数据同步的机会。

另外master挂掉后，slave仍为slave状态，master重启后，会保留主从关系。

### 反客为主

master挂掉，由一个slave出来作为master。

可以在slave上使用slaveof no one将当前slave升级为master。

这里是手动进行slave到master身份的切换，而它的自动版被称为哨兵模式。

### 哨兵模式

能够后台监控master是否故障，如果故障则根据投票数自动将slave转换为master。

1. 在/myredis目录下新建sentinel.conf文件，写入sentinel monitor mymaster 127.0.0.1 6379 1，其中mymaster是我们为主服务器命名的名称，1表示至少有多少个哨兵同意迁移的数量。
2. 执行redis-sentinel /myredis/sentinel.conf

当主机挂掉后，会从slave中产生新的master，而原主机重连后则会变为从机。

从机选择条件：

1. 选择优先级靠前的。(配置文件中replica-priority值越小，优先级越高。)
2. 选择偏移量最大的。(谁的数据和主机同步率最高。)
3. 选择runID最小的。(runID在每个redis服务启动时是随机生成的。)

### 复制延时

由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重。

## 集群

1. 容量不够，如何扩容？
2. 并发写操作，redis如何分摊？

主从复制下，主机宕机，导致IP地址发生变化(从机晋升为主机后，端口号发生了改变)，此时需要修改应用程序中的地址信息。

早期集群是通过代理主机的方式，即每个模块和代理主机都有主从机制，然后通过代理主机对请求进行转发。

无中心化集群的意思是任意一个模块都可以作为集群入口，如果当前请求不是当前模块负责的，则对该请求进行转发。

redis集群实现了对redis的水平扩容，即启动N个redis节点，将整个数据库分布存储在这N个节点中，每个节点存储总数据的1/N。

redis集群通过分区来提供一定程度的可用性：即使集群中有一部分节点失效或者无法进行通讯，集群也可以继续处理命令请求。

Redis replication -> 主从架构 -> 读写分离 -> 水平扩容支撑读高并发

### 集群配置实例

```text
开启daemonize，关闭appendonly，删除原有的RDB和AOF文件。
准备6个配置文件，内容格式为，其中端口号的替代在vim中可以使用:%s/6379/6380快速查找替换。
include /myredis/redis.conf
pidfile "/var/run/redis_6379.pid"
port 6379
dbfilename "dump6379.rdb"
cluster-enabled yes
cluster-config-file nodes-6379.conf
cluster-node-timeout 15000
启动6个redis服务实例，查看目录下是否生成了集群配置文件
找到redis安装文件目录，不是安装目录，找到src文件夹，执行命令：
redis-cli --cluster create --cluster-replicas 1 192.168.136.128:6379 192.168.136.128:6380 192.168.136.128:6381 192.168.136.128:6389 192.168.136.128:6390 192.168.136.128:6391，必须使用真实IP，不要使用127.0.0.1。
--cluster-replicas 1 表示以最简单的方式配置集群，一主一从。
执行后会显示配置好的master和slave信息，输入yes启动集群，会输出一行[OK] All 16384 slots covered.语句。
使用redis-cli -c -p 6379连上该无中心集群的任意一个节点。
使用cluster nodes命令可以查看集群信息。
```

关于`[OK] All 16384 slots covered.`语句的解释：这表示一个redis集群包含了16384个hash slot，集群使用公式CRC16(key)%16384计算key属于哪个slot，然后每个主节点都会负责这些slots中的一部分，然后就根据计算出来的值判断当前key需要存放到哪个主节点里。

一个集群至少需要三个主节点，实际生产环境中，主节点和从节点之间最好都分布在不同的主机上。

### 集群操作

当我在某个节点上进行操作时，会有相应的提示说当前key被放到了哪个节点，并且直接将当前命令行切换到了对应节点上，因为这是一个无中心集群，并且属于水平分库的概念。

简单地操作单个key，集群可以直接计算hash并定位slot，而对于多个key的同时操作，就需要额外一点操作。

mset name lucy age 20 ==> mset name{user} lucy age{user} 20，意思就是将name和age这两个key放在一个组中，对这个组进行hash计算。

cluster keyslot k1 查找key的slot

cluster countkeysinslot slot 查看slot中key的数量，这要求必须在负责该slot的节点上执行才能查看到数量

slave不会过期key，当master上的key过期时，发送del命令通知slave删除key。

### 故障恢复

假设当前共有一主一从三组共6台主机，如果主节点下线，此时从节点会自动升为主节点，有15S的超时。

主节点恢复后会自动变为从节点。

如果负责某部分slots的主从都挂掉，而cluster-require-full-coverage为yes，那么整个集群都直接挂掉。

如果cluster-require-full-coverage为no，那么该部分slots全都不能使用，也无法存储。

### 集群优缺点

优点：

- 实现扩容
- 分摊压力
- 无中心化配置简单(所有节点之间能够互相切换，只需要配置其中一个入口即可)

缺点：

- 多键操作需要额外操作
- 多键的事务不被支持，LUA脚本不被支持
- 由于集群方案较晚，多个公司已经使用代理或者客户端分片的方式，而想要迁移到redis cluster，需要整体迁移而不是逐步过渡，复杂度较大。

## 缓存三问

### 缓存穿透

现象：

1. 应用服务器压力变大。
2. redis命中率降低。
3. 一直查询数据库。

原因：访问的数据既不在缓存也不在数据库，因为不在数据库也就无法同步缓存，无法同步缓存就导致无法命中缓存，造成数据库压力陡增。

解决方案：

1. 对空值也进行缓存，即数据库返回null，那就把null也进行缓存，但是过期时间可以设置得较短。不是很好
2. 设置可访问名单，比如使用bitmaps，将请求ID作为bitmaps的偏移量，每次访问都进行比较，如果不存在就不允许访问数据库。不是很好
3. 采用布隆过滤器，底层也是bitmaps，将所有可能存在的数据哈希到其中，一定不存在的数据会被这个过滤器进行拦截。
4. 进行实时监控，当发现redis命中率降低，查看访问对象和数据，设置黑名单限制服务。

### 缓存击穿

现象：

1. 数据库访问压力“瞬时”增加。
2. redis没有出现大量的key过期。
3. redis正常运行。

原因：redis中某个热点key忽然过期。

方案：

1. 预先设置热门数据：加大热门key的过期时间。
2. 实时调整：监控数据热门程度，实时调整key的过期时间。
3. 使用排它锁：查询redis key =》返回空=》设置排它锁 set mutex_key 1 EX 180 NX
    - =》成功=》查数据库，同步缓存，删除排它锁。
    - =》失败=》排它锁已经被其它客户端请求建立，正在进行查数据库以及缓存同步。

### 缓存雪崩

现象：

1. 数据库压力变大。

原因：在极少时间段内，大量key集中过期的情况。

解决方案：

1. 构建多级缓存：nginx+redis+ehcahe等。
2. 使用锁或队列：用锁或者队列保证不会有大量请求同时对数据库一次性进行读写，不适合高并发情况。
3. 设置过期标志更新缓存：记录缓存是否过期，如果过期则触发另外线程更新过期时间。
3. 将缓存失效时间错开。

## 分布式锁

随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！

主流方案：

1. 基于数据库
2. 基于redis(性能最高)
3. 基于zookeeper(可靠性最好)

1. 使用setnx上锁，通过del释放锁，这个锁应该和业务逻辑无关，属于临时创建的一个key值。
2. 设置key过期时间，防止锁一直无法释放。
    - `set mutex_key 1 nx ex 60`

### 分布式锁的一个锁误删问题

创建锁并建立过期时间=》进行业务操作=》主动释放锁。

假设A请求在业务操作时发生了长时间的停留，此时锁因为到达过期时间而被自动释放。

此时B请求获取到了锁并进行业务操作，然后A请求此时完成了业务操作，并主动释放了锁，这就导致B的锁被误删除。

使用UUID作为互斥锁的value，防止误删除。

在设置互斥锁时，生成一个UUID作为value，在主动释放锁时，先获取value，判断是否一致，如果一致才选择删除。

这样就是其它请求在锁过期后获得了锁，但会设置其它不同的UUID，因此后续主动释放锁时就不会选择删除。

### 锁误删的一个原子性问题

比如A请求获取到互斥锁的value后，比对UUID发现正确，正准备执行删除操作，但是此时锁到了过期时间，锁被删除，B请求获取到了锁并设置了不同的UUID，但是A请求后续继续执行了删除操作，依旧发生了锁误删的操作。

可以使用LUA脚本，将UUID判断和锁删除作为一个原子性事件进行操作。

### 分布式锁的实现

1. 互斥性，任意时刻，只有一个客户端能持有锁。
2. 不会死锁，即使一个客户端因为崩溃导致没有释放锁，后续客户端也能获取锁。
3. 加锁和解锁必须是同一个客户端。
4. 加锁和解锁必须具有原子性。

### RedLock

基于上述setnx+过期时间+UUID+LUA脚本的分布式锁在单个服务实例时能够较好工作。

但是在主从复制时，如果主机挂掉(key没了，且之前还没同步到从节点)，此时从节点切换为主节点，别人依旧可以set key，从而拿到锁。

假设有一个redis cluster，有5个master实例，执行如下步骤去获取一把锁：

1. 获取当前时间戳，单位是毫秒；
2. 轮流尝试在每个 master 节点上创建锁，超时时间较短，一般就几十毫秒（客户端为了获取锁而使用的超时时间比自动释放锁的总时间要小。例如，如果自动释放时间是 10 秒，那么超时时间可能在 5~50 毫秒范围内）；
3. 尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点 n / 2 + 1 ；
4. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
5. 要是锁建立失败了，那么就依次将之前建立过的锁删除；
6. 只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。

## 多线程

因为读写网络的Read/Write系统调用在Redis执行期间占用了大部分CPU时间，如果把网络读写做成多线程的方式对性能会有很大提升。

redis在6.0加入的多线程是用在网络数据读写和协议解析上，而执行命令部分仍然是单线程。

## 为什么事务不支持回滚

对于运行时错误，只有对某个键执行不符合其类型的命令时才会发生，也就是程序代码错误，这种错误只有在开发阶段才会发生，很少在生产环境中发生。因此，为了保持Redis的简单性，不提供回滚功能。

## 管道、事务、脚本

什么时候使用管道：

1. 提升性能
2. 批量指令
3. 不需要先前命令的响应作为后续命令的输入

什么时候使用事务：

1. 需要原子执行命令
2. 不需要中间值组成后续命令

什么时候使用脚本：

1. 需要原子执行命令
2. 需要中间值组成后续命令
3. 需要中间值来有条件地执行后续命令

也是为什么分布式锁最后会使用LUA脚本来保证删除的原子性。

也是为什么会使用LUA脚本来解决库存遗留问题。

[参考](https://rafaeleyng.github.io/redis-pipelining-transactions-and-lua-scripts)

## 缓存一致性

最经典的缓存+数据库读写模式，即cache aside pattern：

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，先更新数据库，然后再删除缓存。

这是一个lazy的思想，等真正需要用到缓存的时候再选择将数据放到缓存里。

如果更新数据库成功，但缓存删除失败，这就会导致缓存中是旧数据。

解决方案是先删除缓存，再更新数据库，这样即使数据库更新失败，那数据库依旧为旧数据，缓存为空，数据不会不一致。

为什么使用缓存？高性能、高并发。

缓存使用不当会出现双写不一致、缓存三问、缓存并发竞争。

## 过期策略

为什么数据过期了，依旧占用着内存。

- 定期删除，指的是Redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。
- 惰性删除，在你获取某个key的时候，Redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。

如果定期删除漏掉了很多过期key，然后你也没及时去查，也就没走惰性删除，此时会怎么样？如果大量过期key堆积在内存里，导致Redis内存块耗尽了，咋整？

走内存淘汰机制。

allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key（这个是最常用的）。
